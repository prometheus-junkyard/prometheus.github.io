<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="An open-source monitoring system with a dimensional data model, flexible query language, efficient time series database and modern alerting approach.">
    <meta name="keywords" content="prometheus, monitoring, monitoring system, time series, time series database, alerting, metrics, telemetry">
    <meta name="author" content="Prometheus">

    <link rel="alternate" type="application/atom+xml" title="Prometheus Blog » Feed" href="/blog/feed.xml">

    <link rel="shortcut icon" href="/assets/favicons/favicon.ico">
    <link rel="apple-touch-icon" sizes="57x57" href="/assets/favicons/apple-touch-icon-57x57-cbe16921e26.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/assets/favicons/apple-touch-icon-60x60-cb34684d423.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/assets/favicons/apple-touch-icon-72x72-cb804bd5fae.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/assets/favicons/apple-touch-icon-76x76-cb4a7d77a78.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/assets/favicons/apple-touch-icon-114x114-cbb4144a5d4.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/assets/favicons/apple-touch-icon-120x120-cb24b29faf0.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/favicons/apple-touch-icon-144x144-cb590f03c01.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/assets/favicons/apple-touch-icon-152x152-cbb45d875fa.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/assets/favicons/apple-touch-icon-180x180-cb5da064c37.png">
    <link rel="icon" type="image/png" href="/assets/favicons/favicon-32x32-cb6bc898e38.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/assets/favicons/android-chrome-192x192-cbd9b99e56f.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/assets/favicons/favicon-96x96-cbe466ffcf9.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/assets/favicons/favicon-16x16-cb02406aa58.png" sizes="16x16">
    <link rel="manifest" href="/assets/favicons/android-chrome-manifest.json">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="msapplication-TileImage" content="/assets/favicons/mstile-144x144.png">
    <meta name="theme-color" content="#ffffff">

    
    <title>Interview with Compose | Prometheus</title>
    

    <!-- Bootstrap core CSS -->
    <link href="/assets/bootstrap-3.3.1/css/bootstrap.min-cb3ab3438f8.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="/css/docs-cb74caebabb.css" rel="stylesheet">
    <link href="/css/routing-tree-editor-cbd4d13cac6.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="/assets/font-awesome-4.2.0/css/font-awesome.min-cbfeda974a7.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Lato:300,300italic,400' rel='stylesheet' type='text/css'>

  </head>

  <body>

  <div class="">
    <nav class="navbar navbar-inverse navbar-static-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="/"><img src="/assets/prometheus_logo_grey.svg" alt="Prometheus logo"> Prometheus</a>
        </div>
        <div class="collapse navbar-collapse" id="navbar">
          <ul class="nav navbar-nav navbar-right main-nav">
            <li><a href="/docs/introduction/overview/">Docs</a></li>
            <li><a href="/download/">Download</a></li>
            <li><a href="/community/">Community</a></li>
            <li><a href="/blog/">Blog</a></li>
            <li><a href="https://github.com/prometheus"><i class="fa fa-github"></i></a></li>
            <li><a href="https://twitter.com/PrometheusIO"><i class="fa fa-twitter"></i></a></li>
          </ul>
        </div>
      </div>
    </nav>
  </div>


<div class="container">
  
<div class="row">
  <div class="col-md-9 blog doc-content">
    <h1>Interview with Compose</h1>
    <aside>Posted at: September 21, 2016 by Brian Brazil</aside>
    <article class="doc-content">
      <p><em>Continuing our series of interviews with users of Prometheus, Compose talks
about their monitoring journey from Graphite and InfluxDB to Prometheus.</em></p>

<h2 id="can-you-tell-us-about-yourself-and-what-compose-does?">Can you tell us about yourself and what Compose does?<a class="header-anchor" href="#can-you-tell-us-about-yourself-and-what-compose-does" name="can-you-tell-us-about-yourself-and-what-compose-does"></a>
</h2>

<p><a href="https://www.compose.com/">Compose</a> delivers production-ready database clusters
as a service to developers around the world. An app developer can come to us
and in a few clicks have a multi-host, highly available, automatically backed
up and secure database ready in minutes. Those database deployments then
autoscale up as demand increases so a developer can spend their time on
building their great apps, not on running their database.</p>

<p>We have tens of clusters of hosts across at least two regions in each of AWS,
Google Cloud Platform and SoftLayer. Each cluster spans availability zones
where supported and is home to around 1000 highly-available database
deployments in their own private networks. More regions and providers are in
the works.</p>

<h2 id="what-was-your-pre-prometheus-monitoring-experience?">What was your pre-Prometheus monitoring experience?<a class="header-anchor" href="#what-was-your-pre-prometheus-monitoring-experience" name="what-was-your-pre-prometheus-monitoring-experience"></a>
</h2>

<p>Before Prometheus, a number of different metrics systems were tried. The first
system we tried was <a href="https://graphiteapp.org/">Graphite</a>, which worked pretty
well initially, but the sheer volume of different metrics we had to store,
combined with the way Whisper files are stored and accessed on disk, quickly
overloaded our systems. While we were aware that Graphite could be scaled
horizontally relatively easily, it would have been an expensive cluster.
<a href="https://www.influxdata.com/">InfluxDB</a> looked more promising so we started
trying out the early-ish versions of that and it seemed to work well for a good
while. Goodbye Graphite. </p>

<p>The earlier versions of InfluxDB had some issues with data corruption
occasionally. We semi-regularly had to purge all of our metrics. It wasn’t a
devastating loss for us normally, but it was irritating. The continued promises
of features that never materialised frankly wore on us.</p>

<h2 id="why-did-you-decide-to-look-at-prometheus?">Why did you decide to look at Prometheus?<a class="header-anchor" href="#why-did-you-decide-to-look-at-prometheus" name="why-did-you-decide-to-look-at-prometheus"></a>
</h2>

<p>It seemed to combine better efficiency with simpler operations than other
options.</p>

<p>Pull-based metric gathering puzzled us at first, but we soon realised the
benefits. Initially it seemed like it could be far too heavyweight to scale
well in our environment where we often have several hundred containers with
their own metrics on each host, but by combining it with Telegraf, we can
arrange to have each host export metrics for all its containers (as well as its
overall resource metrics) via a single Prometheus scrape target.</p>

<h2 id="how-did-you-transition?">How did you transition?<a class="header-anchor" href="#how-did-you-transition" name="how-did-you-transition"></a>
</h2>

<p>We are a Chef shop so we spun up a largish instance with a big EBS volume and
then reached right for a <a href="https://github.com/rayrod2030/chef-prometheus">community chef
cookbook</a> for Prometheus.</p>

<p>With Prometheus up on a host, we wrote a small Ruby script that uses the Chef
API to query for all our hosts, and write out a Prometheus target config file.
We use this file with a <code>file_sd_config</code> to ensure all hosts are discovered and
scraped as soon as they register with Chef. Thanks to Prometheus’ open
ecosystem, we were able to use Telegraf out of the box with a simple config to
export host-level metrics directly.</p>

<p>We were testing how far a single Prometheus would scale and waiting for it to
fall over. It didn’t! In fact it handled the load of host-level metrics scraped
every 15 seconds for around 450 hosts across our newer infrastructure with very
little resource usage.</p>

<p>We have a lot of containers on each host so we were expecting to have to start
to shard Prometheus once we added all memory usage metrics from those too, but
Prometheus just kept on going without any drama and still without getting too
close to saturating its resources. We currently monitor over 400,000 distinct
metrics every 15 seconds for around 40,000 containers on 450 hosts with a
single m4.xlarge prometheus instance with 1TB of storage. You can see our host
dashboard for this host below. Disk IO on the 1TB gp2 SSD EBS volume will
probably be the limiting factor eventually. Our initial guess is well
over-provisioned for now, but we are growing fast in both metrics gathered and
hosts/containers to monitor.</p>

<p><img src="/assets/blog/2016-09-21/compose-host-dashboard-cb97623cae4.png" alt="Prometheus Host Dashboard"></p>

<p>At this point the Prometheus server we’d thrown up to test with was vastly more
reliable than the InfluxDB cluster we had doing the same job before, so we did
some basic work to make it less of a single-point-of-failure. We added another
identical node scraping all the same targets, then added a simple failover
scheme with keepalived + DNS updates. This was now more highly available than
our previous system so we switched our customer-facing graphs to use Prometheus
and tore down the old system.</p>

<p><img src="/assets/blog/2016-09-21/compose-memory-stats-cb6c2d95184.png" alt="Prometheus-powered memory metrics for PostgresSQL containers in our app"></p>

<h2 id="what-improvements-have-you-seen-since-switching?">What improvements have you seen since switching?<a class="header-anchor" href="#what-improvements-have-you-seen-since-switching" name="what-improvements-have-you-seen-since-switching"></a>
</h2>

<p>Our previous monitoring setup was unreliable and difficult to manage. With
Prometheus we have a system that’s working well for graphing lots of metrics,
and we have team members suddenly excited about new ways to use it rather than
wary of touching the metrics system we used before.</p>

<p>The cluster is simpler too, with just two identical nodes. As we grow, we know
we’ll have to shard the work across more Prometheus hosts and have considered a
few ways to do this.</p>

<h2 id="what-do-you-think-the-future-holds-for-compose-and-prometheus?">What do you think the future holds for Compose and Prometheus?<a class="header-anchor" href="#what-do-you-think-the-future-holds-for-compose-and-prometheus" name="what-do-you-think-the-future-holds-for-compose-and-prometheus"></a>
</h2>

<p>Right now we have only replicated the metrics we already gathered in previous
systems - basic memory usage for customer containers as well as host-level
resource usage for our own operations. The next logical step is enabling the
database teams to push metrics to the local Telegraf instance from inside the
DB containers so we can record database-level stats too without increasing
number of targets to scrape.</p>

<p>We also have several other systems that we want to get into Prometheus to get
better visibility. We run our apps on Mesos and have integrated basic Docker
container metrics already, which is better than previously, but we also want to
have more of the infrastructure components in the Mesos cluster recording to
the central Prometheus so we can have centralised dashboards showing all
elements of supporting system health from load balancers right down to app
metrics.</p>

<p>Eventually we will need to shard Prometheus. We already split customer
deployments among many smaller clusters for a variety of reasons so the one
logical option would be to move to a smaller Prometheus server (or a pair for
redundancy) per cluster rather than a single global one.</p>

<p>For most reporting needs this is not a big issue as we usually don’t need
hosts/containers from different clusters in the same dashboard, but we may keep
a small global cluster with much longer retention and just a modest number of
down-sampled and aggregated metrics from each cluster’s Prometheus using
Recording Rules.</p>

    <article>

    <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES * * */
        var disqus_shortname = 'prometheus-blog';
     
        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
  </div>

  <div class="col-md-3 side-nav-col">
  <ul class="nav navbar-nav side-nav">
    <li>
      <span class="nav-header">Blog posts</span>
      <ul class="nav active">
      
        <li><a href="/blog/2017/09/04/promcon-2017-recap/">PromCon 2017 Recap</a></li>
      
        <li><a href="/blog/2017/06/21/prometheus-20-alpha3-new-rule-format/">Prometheus 2.0 Alpha.3 with New Rule Format</a></li>
      
        <li><a href="/blog/2017/06/14/interview-with-latelier-animation/">Interview with L’Atelier Animation</a></li>
      
        <li><a href="/blog/2017/05/17/interview-with-iadvize/">Interview with iAdvize</a></li>
      
        <li><a href="/blog/2017/04/10/promehteus-20-sneak-peak/">Sneak Peak of Prometheus 2.0</a></li>
      
        <li><a href="/blog/2017/04/06/interview-with-europace/">Interview with Europace</a></li>
      
        <li><a href="/blog/2017/02/20/interview-with-weaveworks/">Interview with Weaveworks</a></li>
      
        <li><a href="/blog/2016/11/16/interview-with-canonical/">Interview with Canonical</a></li>
      
        <li><a href="/blog/2016/10/12/interview-with-justwatch/">Interview with JustWatch</a></li>
      
        <li><a href="/blog/2016/09/21/interview-with-compose/">Interview with Compose</a></li>
      
        <li><a href="/blog/2016/09/14/interview-with-digitalocean/">Interview with DigitalOcean</a></li>
      
        <li><a href="/blog/2016/09/07/interview-with-shuttlecloud/">Interview with ShuttleCloud</a></li>
      
        <li><a href="/blog/2016/09/04/promcon-2016-its-a-wrap/">PromCon 2016 - It's a wrap!</a></li>
      
        <li><a href="/blog/2016/07/23/pull-does-not-scale-or-does-it/">Pull doesn't scale - or does it?</a></li>
      
        <li><a href="/blog/2016/07/18/prometheus-1-0-released/">Prometheus reaches 1.0</a></li>
      
        <li><a href="/blog/2016/05/09/prometheus-to-join-the-cloud-native-computing-foundation/">Prometheus to Join the Cloud Native Computing Foundation</a></li>
      
        <li><a href="/blog/2016/05/08/when-to-use-varbit-chunks/">When (not) to use varbit chunks</a></li>
      
        <li><a href="/blog/2016/05/01/interview-with-showmax/">Interview with ShowMax</a></li>
      
        <li><a href="/blog/2016/03/23/interview-with-life360/">Interview with Life360</a></li>
      
        <li><a href="/blog/2016/03/03/custom-alertmanager-templates/">Custom Alertmanager Templates</a></li>
      
        <li><a href="/blog/2016/01/26/one-year-of-open-prometheus-development/">One Year of Open Prometheus Development</a></li>
      
        <li><a href="/blog/2015/08/17/service-discovery-with-etcd/">Custom service discovery with etcd</a></li>
      
        <li><a href="/blog/2015/06/24/monitoring-dreamhack/">Monitoring DreamHack - the World's Largest Digital Festival</a></li>
      
        <li><a href="/blog/2015/06/18/practical-anomaly-detection/">Practical Anomaly Detection</a></li>
      
        <li><a href="/blog/2015/06/01/advanced-service-discovery/">Advanced Service Discovery in Prometheus 0.14.0</a></li>
      
        <li><a href="/blog/2015/04/24/prometheus-monitring-spreads-through-the-internet/">Prometheus Monitoring Spreads through the Internet</a></li>
      
      </ul>
    </li>
  </ul>
</div>

</div>

  <hr>

<footer>
  <p class="pull-left">
    &copy; Prometheus Authors 2017
  </p>
</footer>

</div>

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://code.jquery.com/jquery-2.2.2.min.js" integrity="sha256-36cp2Co+/62rEAAYHLmRCPIych47CvdM+uTBJwSzWjI=" crossorigin="anonymous"></script>
    <script src="/assets/bootstrap-3.3.1/js/bootstrap.min-cb2616d3564.js"></script>
    <script src="/assets/docs-cb53fb1bfd3.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="/assets/ie10-viewport-bug-workaround-cbb5a0dd7ce.js"></script>
    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-58468480-1', 'auto');
      ga('send', 'pageview');
    </script>
  </body>
</html>


